%=================================================================
\section{Introduction}\label{sec-intro}

Data is the new oil for the industry and
it can be used for empowering processes with
new business-related insights
(e.g. to define new customer groups through predictive analytics).
At the same time data is a critical asset of a company and
can be used for detecting the anomaly behavior or event
such as for
intrusion detection,
fraud detection,
fault detection,
event detection in sensor networks,
and detecting eco-system disturbances.

Anomalies are also refered as outlier in the
data mining literature.
Hawkins~\cite{hawkins1980identification} defined
an outlier as follows:
``An outlier is an observation which
deviates so much from the other observations
as to arouse suspicions that
it was generated by a different mechanism.''
Based on this definiton,
two general approaches exist for the anomaly
detection in the industry:
rule-based method,
where we manually define some rules of
well-known anomaly behavior
with prior knowledge,
and data-based anomaly detection,
where looking for behavior that
is out of the normal.

The Rule-based method works reliably on known anomaly behavior,
but has the obvious disadvantage of not being capable of
detecting new anomaly behavior.
The data-based anomaly detection model works by
identifying anomalies by creating a model of
the normal patterns in the data,
and then compute an outlier score of a given data point
on the basis of the deviations from these patterns.
The main advantage of data-based anomaly detection is that
it does not require prior knowledge of an intrusion and
thus can detect new anomaly behavior.

Although many anomaly detection methods have been proposed,
there still serverl challenges of anomaly detection exist
in the practical  process of industry:
\begin{enumerate}
    \item Few or no labeled data sets.
    \item Anomaly Detecion in Data stream.
    In the practical process of industry,
    the value of dataset is usually infinity.
    \item Explaining anomaly detection.
    To make  user convince and help them make decision,
    the proposed method could not only identify anomalies  but also
    why.
\end{enumerate}
This paper aims to review data-based anomaly detection methods and
identify unspervisd anomaly detection,
data stream anomaly, and explaining anomaly detection
to solve challenges above.

The rest of the chapter is organised as follows.
We first introduce the existing methods of classic anomaly detection,
in the Section~\ref{sec-method},
Then,
we introdeuce the anomaly detect method in the Section~\ref{sec-data_stream}.
In the Section~\ref{sec-explain_anomaly},
we introdeuce the explaining anomaly detect method.
Section~\ref{sec:tools} introduce the published tools of
methods of anomaly detection,
followed by the conclusions in the last section.

\section{Method of Anomaly Detection}~\label{sec-method}

\subsection{Statistical Based Methods}

Anomaly detection based on statistical is the earliest and
most studied approach.
It considers that the difference
between the data and the statistical distribution or the model
given is bigger than a particular value or range that is
anomaly~\cite{chandola2009anomaly}.
This method can be divided into two
categories: distribution-based method and depth-based
method.

The distribution-based method assigns a distribution (such as
normal distribution,
Poisson distribution,
etc.),
and then the anomaly is found by the method of consistency checking.
The vast majority tests of anomaly detection based on
distribution are for a single attribute while a large number
of abnormal data mining in reality is carried out in a
multidimensional space.
In addition,
the actual distribution of the data set is often unknown,
and it is difficult to
estimate the data distribution in high-dimensional;


The depth-based method considers that
each object is a point in n-dimensional space,
each point has one set depth,
and anomaly possibly exists in the object which has lower depth.
This process avoids the data distribution fitting problem of
distribution method of distribution based method.
But it needs to calculate
the convex closure of n-dimensional space and has higher
calculation complexity,
only suitable for low dimensional
data like two dimensional or three,
and has a low efficiency
on large data sets with four or higher dimensions~\cite{ruts1996computing}.

\subsection{Distance Based Methods}

The basic thought of anomaly detection based on
distance is to calculate the distance between data points in
data space by setting a distance function.
It is regarded as
abnormal when there is a large distance between a data
object and others.
Knorr et al.
firstly proposed an anomaly
detection method based on distance~\cite{knorr1997unified}.
They consider o as,
exception if the distance between object o and
p objects at least is greater than d.
And then,
the concept of this distance is extended to k-neighbor distance.
K-neighbor distance of each object is calculated and
sorted from small to big by Ramaswamy et al,
the objects which have largest
distance are considered abnormal~\cite{ramaswamy2000efficient} .

The anomaly detection based on distance combines the ideas
based on distribution,
overcomes the primary disadvantages
of anomaly detection based on distribution,
is easier to realize and comprehend,
and is widely studied and used.
But it has its own drawbacks.
Firstly,
the complexity of the algorithm is relatively high,
and it cannot take into account
the data size of data sets and the scalability of dimension.
Secondly,
Breunig et al.
pointed out anomaly detection based on distance is flawed in
processing the data sets with obvious internal density
differences~\cite{breunig2000lof}.
It either considers the data in the area of sparse
density to be abnormal or
it cannot find some anomalous.
This is mainly because of the anomaly detection based on
distance considers all the viewpoints,
its capability is not good in processing the data which
contains a variety of distribution or
are mixed with different densities subset.
In addition,
anomaly detection based on distance is very
sensitive to parameters p and d,
which requires the users
having a certain expertise to set the reasonable parameters.
So,
its practical application is limited.

\subsection{Density Based Methods}
All the methods above have a common problem,
that is,
a global distance criterion is considered as
the basis for anomaly detection.
In fact,
the anomaly is usually detected
from the perspective of individual,
that is,
the anomaly point is far from its neighbor cluster.
So it is not appropriate
to use global distance.
To solve this problem,
several anomaly detection
algorithm based
on density is proposed .
Its basic idea is detecting anomaly by comparing
the density of object and its neighbor.
Breunig et al. introduce local
outlier factor (LOF),
considers the exception is not a
two-value property but a measure.
The LOF value higher,
the data is more likely to be abnormal~\cite{breunig2000lof}.
Agyemang et al.
proposed local sparsity coefficient (LCF) to
detect anomaly and reduce
the computational complexity by considering
the largest distance between the nearest k objects as
k-distance~\cite{agyemang2004algorithm}.
Furthermore,
Papadimitriou et al. got multi-granularity
deviation factor (MDEF) by
comparing the number of data objects in r-neighbor and
their mean values,
took it the measure of abnormal~\cite{papadimitriou2003loci}.
This method does not need to calculate the density of data
points,
and the computational efficiency is higher than LOF.
The idea based on density is closer to Hawkins’ exception
definition~\cite{hawkins1980identification}
than the idea based on distance.
So it can detect the local anomaly,
reduce the detection error which contains
a variety of distribution or are mixed with different
densities subset,
have a higher detection precision.
However,
its time complexity is still high,
the detection
results are sensitive to the selection of the parameters like
outlier factor threshold and the parameters are difficult to
determine.
\subsection{Ensembles Based Methods}

Ensemble methods train multiple learners and
then combine them for use~\cite{zhou2012ensemble}.
They have already achieved great success in many
real-world tasks.
\xhanMarker


\section{Anomaly detection for data stream}
\label{sec-data_stream}



\section{Explain anomaly detection}
\label{sec-explain_anomaly}
Explaining anomaly detection is the task of making
the anomaly detection process more transparent to the users,
i.e. why are these samples are recorded as anomalies?
% The Explaining anomaly detection task refers to
% making users fully understand the anomaly behavior.
% However,
The  goal of explanation is not only to
convince the users about the proposed anomoaly detection method,
but also helping the users to understand behavior about
the .
This process will help the users to make decision such as
adjusting some feature of sample according to propsed method to
make the anomalier to normal.

In the last decade,
a few methods have been developed to explain predictions
from supervised models.
One approach uses an interpretable approximation of
the original model~\cite{lundberg2017unified};
examples of methods that
use an interpretable approximation
of the original model include: LIME~\cite{ribeiro2016should},
which is an example of a
model-agnostic method used to
explain a prediction using a local model,
and DeepLIFT~\cite{shrikumar2017learning},
which is an example of a model-specific method for explaining
deep learning models in which
the contributions of all neurons in the network are
back-propagated to the input features.
SHAP - SHapley Additive exPlanation ~\cite{lundberg2017unified}
combines previous methods for
explaining predictions by calculating feature
importance,
using Shapley values from
game theory that ensures consistency of
the explanations.



% Unlike classic anomoaly detection method,
% debate and negotiation are often necessary for group users,
% and this calls for understanding of not only the pros but also
% the cons of the proposed recommendations.
% While existing explanation approaches focus on
% determining how good the recommendation is for the user,
% it is now desirable to know how bad the recommendation is for each group user.

\section{Evaluation of Anomaly Detection}

After the implementation of anomaly 
detection algorithm,
The next step is to evaluate the 
anomaly detection algorithm.
According to the actual situation, 
we can evaluate the procedural law 
from two aspects: supervised learning 
and unsupervised learning.

\subsection{Supervised Evaluation}
At present, 
the evaluation methods of supervised learning mainly
include confusion matrix method, accuracy and recall rate,
F1 score,
ROC curve,
AUC,
etc.

\subsubsection{Confusion Matrix}
For example,
for binary classification problems,
all problems are divided into 0 and 1.
The confusion matrix is shown in Table 1,
which is a 2 * 2 matrix.

\begin{table}  \centering
  \caption{Confusion Matrix}
  \label{tbl:overall-experiments}
  \begin{tabular}{ccc}
\toprule
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    & predicted value 0 & predicted value 1  \\
\midrule
    True value 0& TN & FP  \\
    True value 1& FN & TP  \\

\bottomrule
\end{tabular}
\end{table}


TN:
the true value is 0,
and the predicted value is also 0,
that is,
our prediction is negative and the prediction is correct.

FP:
the true value is 0 and the predicted value is 1,
which means that our prediction is positive,
but the prediction is wrong.

FN:
the true value is 1 and the predicted value is 0,
 which means that our prediction is negative,
  but the prediction is wrong.

TP:
the true value is 1 and the predicted value is 1,
which means that our prediction is positive and the
prediction is correct.

\subsubsection{Accuracy  And Recall}

precision:

$$precision=\frac{TP}{TP+FP}$$ 

The accuracy rate is to measure the proportion of
the number of correctly predicted samples to all
 samples predicted as positive.



recall:

$$recall=\frac{TP}{TP+FN}$$ 

Recall rate refers to the number of correctly
predicted samples in all the data with true
value of 1.
\subsubsection{F1 Score}
F1 score is a harmonic average of accuracy and recall:
$$F1=\frac{2*precision*recall}{precision+recall}$$ 
The characteristic of harmonic average is that if
the two are extremely unbalanced,
for example, when one value is extremely
high and the other is extremely low,
the obtained F1 score value is also very low;
only when both of them are very high,
F1 will be high.
\subsubsection{ROC Curve}
TPR:
the recall rate is the percentage of the data
 predicted to be 1 and the correct number in the
 true value of 1.
 $$TPR=recall$$

FPR:
the number of data with a prediction of 1,
but a wrong prediction,
as a percentage of the data whose true value is not 1.
$$FPR=\frac{FP}{TN+FP}$$ 
TPR is proportional to FPR,
and ROC curve is the curve describing these two relationships.
The closer the ROC curve is to the upper left corner,
the better the classifier is.
\subsubsection{AUC}
AUC (area under curve) refers to the area under the ROC curve.
The vertical and horizontal axis ranges are (0,1),
 so the total area is less than 1.
 The larger the AUC,
 the better the classification effect.
\subsection{Unsupervised Evaluation}

For unsupervised learning,
we can take several common methods,
such as comparative evaluation,
generating pseudo tags,
similarity analysis and so on.

\subsubsection{Comparative Evaluation}

For unsupervised learning, 
a common evaluation strategy is to rank the 
results according to the score of outliers, 
and then iteratively set the threshold from 
the first to the last. 
This will form n ancestor values 
(true positive rate and false positive rate), 
and a ROC curve can be obtained. 
The integral AUC of ROC can be used as a measure 
to test the performance.


\subsubsection{Generating Pseudo Tags}

There are a lot of learning efforts to transform 
unsupervised learning into supervised learning, 
and there are now feasible methods. 
Then, 
we can use the evaluation methods of supervised learning, 
such as accuracy.

\subsubsection{Similarity Analysis}

Unsupervised learning often depends 
on the similarity between data, 
which can be expressed as spatial density 
or distance measurement. 
In the evaluation of anomaly detection algorithm, 
it can be assumed that a large number of normal 
data are closely adjacent (can form multiple clusters), 
and outliers are often quite different from these normal points.

\section{Anomaly detection software packages}~\label{sec:tools}
Although many companies have implemented their own Anomaly detection systems
to accommodate their specific business needs,
there are still many free/ open source recommender system
software packages available.
In this section,
we review some popular software packages for practitioners
to build their anomaly detection systems.

\subsection{ADTK}

Anomaly Detection Toolkit (ADTK) (\href{https://adtk.readthedocs.io}{https://adtk.readthedocs.io}) is a Python package for
unsupervised / rule-based time series anomaly detection.

\subsection{PyOdds}

PyODDS (\href{http://pyodds.com/}{http://pyodds.com/}) is an end-to end Python system for
outlier detection with database support.
PyODDS provides outlier detection algorithms,
which support both static and time-series data.

\subsection{PyOD}

PyOD~\cite{zhao2019pyod} (\href{https://pypi.org/project/pyod/}{https://pypi.org/project/pyod/})
is a comprehensive and scalable Python toolkit for
detecting outlying objects in multivariate data.
It contains more than 20 detection algorithms,
including emerging deep learning models and
outlier ensembles.

\subsection{Anomaly Detection Toolbox}

Anomaly Detection Toolbox
(\href{http://dsmi-lab-ntust.github.io/AnomalyDetectionToolbox/}{http://dsmi-lab-ntust.github.io/AnomalyDetectionToolbox/})
collectes a lot of popular outlier detection algorithms in Matlab.

\subsection{DeepADoTS}

DeepADoTS (\href{https://github.com/KDD-OpenSource/DeepADoTS}{https://github.com/KDD-OpenSource/DeepADoTS})
is a benchmarking pipeline for anomaly detection on
time series data for
multiple state-of-the-art deep learning methods.

\subsection{RRCF}

RRCF~\cite{bartos_2019_rrcf} (\href{https://travis-ci.org/github/kLabUM/rrcf}{https://travis-ci.org/github/kLabUM/rrcf})



\section{Conclusions} \label{sec-conclusions}

% \blindtext

% % %\section*{Acknowledgment}

% % \lipsum[1]


% % The authors would like to thank \ldots

